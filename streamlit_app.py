import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import io
import re
import requests  # –î–æ–±–∞–≤–∏–ª–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="YouTube Parser", page_icon="üî¥", layout="centered")

# --- –ü–û–õ–£–ß–ï–ù–ò–ï –°–ï–ö–†–ï–¢–û–í ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    TG_TOKEN = st.secrets["TELEGRAM_TOKEN"]
    TG_CHAT_ID = st.secrets["TELEGRAM_CHAT_ID"]
except:
    st.error("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ Secrets (–ö–ª—é—á–∏ API) –≤ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Streamlit!")
    st.stop()

# --- –§–£–ù–ö–¶–ò–Ø –û–¢–ü–†–ê–í–ö–ò –í TELEGRAM ---
def send_to_telegram(file_data, file_name):
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendDocument"
    files = {'document': (file_name, file_data, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')}
    data = {'chat_id': TG_CHAT_ID, 'caption': f"‚úÖ –§–∞–π–ª –≥–æ—Ç–æ–≤: {file_name}"}
    try:
        requests.post(url, data=data, files=files)
        return True
    except:
        return False

# --- –í–ê–®–ê –ò–ù–ñ–ï–ù–ï–†–ù–ê–Ø –õ–û–ì–ò–ö–ê (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ---
def get_video_id(url):
    url = url.strip()
    if "v=" in url: return url.split("v=")[1].split("&")[0]
    elif "youtu.be/" in url: return url.split("youtu.be/")[1].split("?")[0]
    return url if len(url) == 11 else None

def get_video_title(youtube, video_id):
    try:
        resp = youtube.videos().list(part="snippet", id=video_id).execute()
        return resp['items'][0]['snippet']['title']
    except:
        return f"Video_{video_id}"

def process_videos(api_key, urls):
    youtube = build('youtube', 'v3', developerKey=api_key)
    all_data = []
    logs = []
    file_name = "comments.xlsx"
    
    for i, url in enumerate(urls):
        if not url.strip(): continue
        v_id = get_video_id(url)
        if not v_id:
            logs.append(f"‚ö†Ô∏è –°—Å—ã–ª–∫–∞ {i+1} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞.")
            continue
        if i == 0:
            title = get_video_title(youtube, v_id)
            clean_title = re.sub(r'[\\/*?:"<>|]', "", title)[:50]
            file_name = f"{clean_title}.xlsx"
        
        logs.append(f"üîç –°–∫–∞—á–∏–≤–∞—é: {v_id}...")
        try:
            req = youtube.commentThreads().list(
                part="snippet,replies", videoId=v_id, maxResults=100, order="time"
            )
            counter = 0
            while req:
                resp = req.execute()
                for item in resp['items']:
                    top = item['snippet']['topLevelComment']['snippet']
                    all_data.append({
                        'ID –í–∏–¥–µ–æ': v_id, '–¢–∏–ø': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π', '–ê–≤—Ç–æ—Ä': top['authorDisplayName'],
                        '–¢–µ–∫—Å—Ç': top['textDisplay'], '–õ–∞–π–∫–æ–≤': top['likeCount'], '–î–∞—Ç–∞': top['publishedAt']
                    })
                    counter += 1
                    if 'replies' in item:
                        for reply in item['replies']['comments']:
                            r = reply['snippet']
                            all_data.append({
                                'ID –í–∏–¥–µ–æ': v_id, '–¢–∏–ø': '–û—Ç–≤–µ—Ç', '–ê–≤—Ç–æ—Ä': r['authorDisplayName'],
                                '–¢–µ–∫—Å—Ç': r['textDisplay'], '–õ–∞–π–∫–æ–≤': r['likeCount'], '–î–∞—Ç–∞': r['publishedAt']
                            })
                            counter += 1
                req = youtube.commentThreads().list_next(req, resp)
            logs.append(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {counter} –∑–∞–ø–∏—Å–µ–π.")
        except Exception as e:
            logs.append(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    return all_data, logs, file_name

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title("YouTube Comment Downloader üöÄ")
raw_urls = st.text_area("–°—Å—ã–ª–∫–∏ (–∫–∞–∂–¥–∞—è —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", height=150)

if st.button("–ù–∞—á–∞—Ç—å —Å–±–æ—Ä", type="primary"):
    if not raw_urls.strip():
        st.warning("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫–∏.")
    else:
        with st.spinner('–†–∞–±–æ—Ç–∞—é...'):
            urls = raw_urls.split('\n')
            data, logs, fname = process_videos(API_KEY, urls)
        
        with st.expander("–ñ—É—Ä–Ω–∞–ª —Ä–∞–±–æ—Ç—ã"):
            for log in logs: st.write(log)
        
        if data:
            df = pd.DataFrame(data)
            df['–¢–µ–∫—Å—Ç'] = df['–¢–µ–∫—Å—Ç'].astype(str).str.replace(r'<[^>]*>', ' ', regex=True)
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            
            excel_data = buffer.getvalue()
            
            # –û–¢–ü–†–ê–í–ö–ê –í TELEGRAM (–ù–æ–≤–∞—è —Ñ–∏—à–∫–∞)
            if send_to_telegram(excel_data, fname):
                st.info("üìÇ –ö–æ–ø–∏—è —Ñ–∞–π–ª–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤–∞–º –≤ Telegram!")
            else:
                st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–æ–ø–∏—é –≤ Telegram.")
            
            st.success(f"–ì–æ—Ç–æ–≤–æ! –°–æ–±—Ä–∞–Ω–æ {len(data)} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.")
            st.download_button(label=f"üì• –°–∫–∞—á–∞—Ç—å {fname}", data=excel_data, file_name=fname)
