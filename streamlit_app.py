import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import io
import re
import requests

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="YouTubeComm", page_icon="üìâ", layout="centered")

# --- –°–ï–ö–†–ï–¢–´ ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    TG_TOKEN = st.secrets["TELEGRAM_TOKEN"]
    TG_CHAT_ID = st.secrets["TELEGRAM_CHAT_ID"]
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ Secrets: {e}")
    st.stop()

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ê–ú–Ø–¢–ò (SESSION STATE) ---
# –≠—Ç–æ "–∂–µ—Å—Ç–∫–∏–π –¥–∏—Å–∫" –≤–∞—à–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –î–∞–Ω–Ω—ã–µ –∑–¥–µ—Å—å –Ω–µ –∏—Å—á–µ–∑–∞—é—Ç –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏.
if 'data_processed' not in st.session_state:
    st.session_state['data_processed'] = False
if 'excel_buffer' not in st.session_state:
    st.session_state['excel_buffer'] = None
if 'file_name' not in st.session_state:
    st.session_state['file_name'] = ""
if 'ai_summary' not in st.session_state:
    st.session_state['ai_summary'] = None
if 'model_name' not in st.session_state:
    st.session_state['model_name'] = None

# --- –¢–ï–õ–ï–ì–†–ê–ú ---
def send_results_to_telegram(file_data, file_name, ai_text=None):
    try:
        # 1. –î–æ–∫—É–º–µ–Ω—Ç
        caption = f"üìÇ {file_name}"
        if ai_text: caption += "\n\n(–û—Ç—á–µ—Ç AI –Ω–∏–∂–µ)"
        requests.post(
            f"https://api.telegram.org/bot{TG_TOKEN}/sendDocument", 
            data={'chat_id': TG_CHAT_ID, 'caption': caption}, 
            files={'document': (file_name, file_data)}
        )
        # 2. –¢–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if ai_text:
            url_msg = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
            if len(ai_text) > 4000:
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text[:4000], 'parse_mode': 'Markdown'})
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text[4000:], 'parse_mode': 'Markdown'})
            else:
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text, 'parse_mode': 'Markdown'})
    except: pass

# --- AI –ê–ù–ê–õ–ò–ó ---
def get_ai_summary(comments_list):
    if not comments_list: return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.", None
    
    text_corpus = "\n".join([str(c['–¢–µ–∫—Å—Ç'])[:400] for c in comments_list[:80]])
    
    prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ YouTube.
    –ù–∞–ø–∏—à–∏ –æ—Ç—á–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown.
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
    1. üé≠ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
    2. üî• –¢–µ–º—ã —Å–ø–æ—Ä–æ–≤
    3. üëç –ü–æ–∑–∏—Ç–∏–≤
    4. üëé –ù–µ–≥–∞—Ç–∏–≤
    5. üß† –í—ã–≤–æ–¥
    
    –¢–µ–∫—Å—Ç: {text_corpus}
    """
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ 2.5, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞
    models = ['gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-1.5-pro', 'gemini-1.5-flash']
    
    last_error = ""
    for model in models:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_KEY}"
        try:
            response = requests.post(
                url, 
                json={"contents": [{"parts": [{"text": prompt}]}]}, 
                headers={"Content-Type": "application/json"}
            )
            if response.status_code == 200:
                return response.json()['candidates'][0]['content']['parts'][0]['text'], model
            else:
                last_error = f"{model}: {response.status_code}"
                continue
        except Exception as e:
            last_error = str(e)
            continue
            
    return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ AI: {last_error}", None

# --- –ü–ê–†–°–ò–ù–ì ---
def process_videos(api_key, urls):
    youtube = build('youtube', 'v3', developerKey=api_key)
    all_data = []
    file_name = "comments.xlsx"
    for i, url in enumerate(urls):
        if "v=" in url: v_id = url.split("v=")[1].split("&")[0]
        elif "youtu.be/" in url: v_id = url.split("youtu.be/")[1].split("?")[0]
        else: continue
        try:
            vid_req = youtube.videos().list(part="snippet", id=v_id).execute()
            if vid_req['items']: 
                title = vid_req['items'][0]['snippet']['title']
                file_name = f"{re.sub(r'[^\w\s-]', '', title)[:30]}.xlsx"
            
            req = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=100)
            while req:
                resp = req.execute()
                for item in resp['items']: 
                    all_data.append({
                        '–ê–≤—Ç–æ—Ä': item['snippet']['topLevelComment']['snippet']['authorDisplayName'], 
                        '–¢–µ–∫—Å—Ç': item['snippet']['topLevelComment']['snippet']['textDisplay']
                    })
                req = youtube.commentThreads().list_next(req, resp)
        except: pass
    return all_data, file_name

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---

# 1. –°—Ç–∏–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–ø–æ —Ü–µ–Ω—Ç—Ä—É, —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π)
st.markdown("<h3 style='text-align: center; margin-bottom: 20px;'>YouTubeComm</h3>", unsafe_allow_html=True)

# 2. –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö
raw_urls = st.text_area("–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ:", height=100, placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å—é–¥–∞...")
use_ai = st.toggle("–ü–æ–¥–∫–ª—é—á–∏—Ç—å AI-–∞–Ω–∞–ª–∏–∑", value=False)

# 3. –ö–ù–û–ü–ö–ê –ó–ê–ü–£–°–ö–ê
# –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º callback –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–∂–∞—Ç–∏—è.
if st.button("–ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É", type="primary", use_container_width=True):
    if not raw_urls:
        st.warning("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É")
    else:
        # –°–ë–†–ê–°–´–í–ê–ï–ú –°–¢–ê–†–´–ï –î–ê–ù–ù–´–ï
        st.session_state['data_processed'] = False
        st.session_state['ai_summary'] = None
        
        with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞...'):
            # –ê. –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            data, fname = process_videos(API_KEY, raw_urls.split('\n'))
            
            if data:
                # –ë. –ì–æ—Ç–æ–≤–∏–º Excel
                df = pd.DataFrame(data)
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False)
                
                # –í. –ê–Ω–∞–ª–∏–∑ AI
                summary_text = None
                mod_name = None
                
                if use_ai:
                    summary_text, mod_name = get_ai_summary(data)
                
                # –ì. –°–û–•–†–ê–ù–Ø–ï–ú –í–°–ï –í –ü–ê–ú–Ø–¢–¨ (–í–ê–ñ–ù–û!)
                st.session_state['excel_buffer'] = buffer.getvalue()
                st.session_state['file_name'] = fname
                st.session_state['ai_summary'] = summary_text
                st.session_state['model_name'] = mod_name
                st.session_state['data_processed'] = True # –§–ª–∞–≥ —É—Å–ø–µ—Ö–∞
                
                # –î. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–µ–ª–µ–≥—Ä–∞–º (–æ–¥–∏–Ω —Ä–∞–∑)
                send_results_to_telegram(buffer.getvalue(), fname, summary_text)
                
            else:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –∏–ª–∏ –¥–æ—Å—Ç—É–ø).")

# --- –ë–õ–û–ö –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (–û–¢–û–ë–†–ê–ñ–ê–ï–¢–°–Ø –í–°–ï–ì–î–ê, –ï–°–õ–ò –ï–°–¢–¨ –î–ê–ù–ù–´–ï) ---
# –≠—Ç–æ—Ç –±–ª–æ–∫ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –í–ù–ï –∫–Ω–æ–ø–∫–∏. –û–Ω –Ω–µ –∏—Å—á–µ–∑–Ω–µ—Ç –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏.

if st.session_state['data_processed']:
    st.divider() # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
    
    # 1. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç AI
    if st.session_state['ai_summary']:
        if st.session_state['model_name']:
            st.success(f"–ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤ ({st.session_state['model_name']})")
            st.markdown(st.session_state['ai_summary'])
        else:
            st.error(st.session_state['ai_summary'])
    elif use_ai:
        pass # –ï—Å–ª–∏ AI –±—ã–ª –≤–∫–ª—é—á–µ–Ω, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—É—Å—Ç–æ–π (–æ—à–∏–±–∫–∞ –≤—ã—à–µ)
    else:
        st.info("–¢–∞–±–ª–∏—Ü–∞ –≥–æ—Ç–æ–≤–∞ (–±–µ–∑ AI).")

    # 2. –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–¢–ï–ü–ï–†–¨ –û–ù–ê –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø)
    st.download_button(
        label=f"üì• –°–∫–∞—á–∞—Ç—å {st.session_state['file_name']}",
        data=st.session_state['excel_buffer'],
        file_name=st.session_state['file_name'],
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        type="secondary",
        use_container_width=True
    )
