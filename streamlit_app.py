import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import io
import re
import requests

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="YouTube Parser", page_icon="üöÄ", layout="centered")

# --- –°–ï–ö–†–ï–¢–´ ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    TG_TOKEN = st.secrets["TELEGRAM_TOKEN"]
    TG_CHAT_ID = st.secrets["TELEGRAM_CHAT_ID"]
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ Secrets: {e}")
    st.stop()

# --- –¢–ï–õ–ï–ì–†–ê–ú ---
def send_results_to_telegram(file_data, file_name, ai_text=None):
    try:
        # 1. –î–æ–∫—É–º–µ–Ω—Ç
        caption = f"üìÇ {file_name}"
        if ai_text: caption += "\n\n(–û—Ç—á–µ—Ç AI –Ω–∏–∂–µ)"
        requests.post(
            f"https://api.telegram.org/bot{TG_TOKEN}/sendDocument", 
            data={'chat_id': TG_CHAT_ID, 'caption': caption}, 
            files={'document': (file_name, file_data)}
        )
        # 2. –¢–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if ai_text:
            url_msg = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
            # –†–∞–∑–±–∏–≤–∞–µ–º, –µ—Å–ª–∏ –¥–ª–∏–Ω–Ω—ã–π
            if len(ai_text) > 4000:
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text[:4000], 'parse_mode': 'Markdown'})
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text[4000:], 'parse_mode': 'Markdown'})
            else:
                requests.post(url_msg, json={'chat_id': TG_CHAT_ID, 'text': ai_text, 'parse_mode': 'Markdown'})
    except: pass

# --- AI –ê–ù–ê–õ–ò–ó (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô) ---
def get_ai_summary(comments_list):
    if not comments_list: return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 80 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
    text_corpus = "\n".join([str(c['–¢–µ–∫—Å—Ç'])[:400] for c in comments_list[:80]])
    
    prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ YouTube.
    –ù–∞–ø–∏—à–∏ –æ—Ç—á–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º:
    1. üé≠ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ.
    2. üî• –¢–µ–º—ã —Å–ø–æ—Ä–æ–≤.
    3. üëç –ü–æ–∑–∏—Ç–∏–≤.
    4. üëé –ù–µ–≥–∞—Ç–∏–≤.
    5. üß† –í—ã–≤–æ–¥.
    
    –¢–µ–∫—Å—Ç: {text_corpus}
    """
    
    # –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ô –°–ü–ò–°–û–ö (–°–Ω–∞—á–∞–ª–∞ —Å—Ç–∞–≤–∏–º —Ç—É, —á—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–∞ –≤ —Ç–µ—Å—Ç–µ!)
    models = [
        'gemini-2.5-flash', # –ü–û–ë–ï–î–ò–¢–ï–õ–¨ –¢–ï–°–¢–ê
        'gemini-2.0-flash',
        'gemini-1.5-pro',
        'gemini-1.5-flash'
    ]
    
    last_error = ""
    
    for model in models:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_KEY}"
        try:
            response = requests.post(
                url, 
                json={"contents": [{"parts": [{"text": prompt}]}]}, 
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                # –£—Å–ø–µ—Ö! –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∏–º—è –º–æ–¥–µ–ª–∏
                return response.json()['candidates'][0]['content']['parts'][0]['text'], model
            else:
                last_error = f"{model}: {response.status_code}"
                continue # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é
        except Exception as e:
            last_error = str(e)
            continue
            
    return f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_error}", None

# --- –ü–ê–†–°–ò–ù–ì YOUTUBE ---
def process_videos(api_key, urls):
    youtube = build('youtube', 'v3', developerKey=api_key)
    all_data = []
    file_name = "comments.xlsx"
    for i, url in enumerate(urls):
        if "v=" in url: v_id = url.split("v=")[1].split("&")[0]
        elif "youtu.be/" in url: v_id = url.split("youtu.be/")[1].split("?")[0]
        else: continue
        try:
            vid_req = youtube.videos().list(part="snippet", id=v_id).execute()
            if vid_req['items']: 
                title = vid_req['items'][0]['snippet']['title']
                file_name = f"{re.sub(r'[^\w\s-]', '', title)[:30]}.xlsx"
            
            req = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=100)
            while req:
                resp = req.execute()
                for item in resp['items']: 
                    all_data.append({
                        '–ê–≤—Ç–æ—Ä': item['snippet']['topLevelComment']['snippet']['authorDisplayName'], 
                        '–¢–µ–∫—Å—Ç': item['snippet']['topLevelComment']['snippet']['textDisplay']
                    })
                req = youtube.commentThreads().list_next(req, resp)
        except: pass
    return all_data, file_name

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title("YouTube Parser üöÄ")

# 1. –°—Å—ã–ª–∫–∞
raw_urls = st.text_area("–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ:", height=100)

# 2. –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å AI (–†—É–±–∏–ª—å–Ω–∏–∫)
use_ai = st.toggle("–ü–æ–¥–∫–ª—é—á–∏—Ç—å AI-–∞–Ω–∞–ª–∏–∑ (Gemini)", value=False)

# 3. –ö–Ω–æ–ø–∫–∞
if st.button("–ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É", type="primary"):
    if not raw_urls:
        st.warning("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É")
    else:
        # –≠–¢–ê–ü 1: –°–±–æ—Ä
        with st.spinner('–ü–∞—Ä—Å–∏–Ω–≥...'):
            data, fname = process_videos(API_KEY, raw_urls.split('\n'))
        
        if data:
            summary = None
            
            # –≠–¢–ê–ü 2: AI (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            if use_ai:
                with st.spinner('Gemini –¥—É–º–∞–µ—Ç...'):
                    summary, model_used = get_ai_summary(data)
                
                if model_used:
                    st.success(f"–ì–æ—Ç–æ–≤–æ! (–ú–æ–¥–µ–ª—å: {model_used})")
                    st.markdown(summary)
                else:
                    st.error(summary)
            
            # –≠–¢–ê–ü 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞
            df = pd.DataFrame(data)
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            
            send_results_to_telegram(buffer.getvalue(), fname, summary)
            st.download_button("–°–∫–∞—á–∞—Ç—å Excel", buffer.getvalue(), fname)
            
            if not use_ai:
                st.info("‚úÖ Excel –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram (–±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞).")
