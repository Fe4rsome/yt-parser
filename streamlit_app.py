import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import io
import re
import requests

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="YouTube Parser Debug", page_icon="üõ†Ô∏è", layout="centered")

# --- –°–ï–ö–†–ï–¢–´ ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    TG_TOKEN = st.secrets["TELEGRAM_TOKEN"]
    TG_CHAT_ID = st.secrets["TELEGRAM_CHAT_ID"]
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ Secrets: {e}")
    st.stop()

# --- –§–£–ù–ö–¶–ò–ò –°–í–Ø–ó–ò ---
def send_results_to_telegram(file_data, file_name, ai_text=None):
    try:
        caption = f"üìÇ {file_name}"
        if ai_text: caption += "\n\n(–û—Ç—á–µ—Ç AI –≤–Ω—É—Ç—Ä–∏)"
        requests.post(
            f"https://api.telegram.org/bot{TG_TOKEN}/sendDocument", 
            data={'chat_id': TG_CHAT_ID, 'caption': caption}, 
            files={'document': (file_name, file_data)}
        )
        if ai_text:
            requests.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage", 
                          json={'chat_id': TG_CHAT_ID, 'text': ai_text[:4000], 'parse_mode': 'Markdown'})
    except: pass

# --- –§–£–ù–ö–¶–ò–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò (–°–∞–º–∞—è –≤–∞–∂–Ω–∞—è —Å–µ–π—á–∞—Å) ---
def debug_gemini_connection():
    st.info("üì° –ù–∞—á–∏–Ω–∞—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É...")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∏–¥–∏—Ç –ª–∏ –∫–ª—é—á –º–æ–¥–µ–ª–∏ –≤–æ–æ–±—â–µ
    url_list = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_KEY}"
    try:
        response = requests.get(url_list)
        data = response.json()
        
        if 'error' in data:
            return f"‚ùå **–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ API:**\nCode: {data['error']['code']}\nMessage: {data['error']['message']}"
            
        models = [m['name'] for m in data.get('models', []) if 'generateContent' in m.get('supportedGenerationMethods', [])]
        st.write(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
        
        if not models:
            return "‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –ø—É—Å—Ç! (–í–æ–∑–º–æ–∂–Ω–æ, –≥–µ–æ-–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∫–ª—é—á–∞)"

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å–ø–∏—Å–∫–∞: {e}"

    # 2. –ü—Ä–æ–±—É–µ–º —Å–∞–º—É—é –Ω–∞–¥–µ–∂–Ω—É—é –º–æ–¥–µ–ª—å
    target_model = 'gemini-1.5-flash'
    # –ï—Å–ª–∏ —Ñ–ª—ç—à–∞ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–æ–ø–∞–≤—à—É—é—Å—è
    if not any(target_model in m for m in models):
        target_model = models[0].replace('models/', '')
    
    st.write(f"üß™ –ü—Ä–æ–±—É—é —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ `{target_model}`...")
    
    url_gen = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model}:generateContent?key={GEMINI_KEY}"
    payload = {"contents": [{"parts": [{"text": "Hello, are you working?"}]}]}
    
    try:
        resp = requests.post(url_gen, json=payload, headers={"Content-Type": "application/json"})
        if resp.status_code == 200:
            return f"üéâ **–£–°–ü–ï–•!** AI –æ—Ç–≤–µ—Ç–∏–ª: {resp.json()['candidates'][0]['content']['parts'][0]['text']}"
        else:
            return f"‚ùå **–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ({resp.status_code}):**\n{resp.text}"
    except Exception as e:
        return f"‚ùå –°–±–æ–π –∑–∞–ø—Ä–æ—Å–∞: {e}"

# --- –§–£–ù–ö–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê ---
def get_ai_summary(comments_list):
    if not comments_list: return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."
    text_corpus = "\n".join([str(c['–¢–µ–∫—Å—Ç'])[:400] for c in comments_list[:80]])
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å
    model = 'gemini-1.5-flash'
    prompt = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ YouTube. –ö—Ä–∞—Ç–∫–æ: 1. –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ. 2. –¢–µ–º—ã. 3. –í—ã–≤–æ–¥. –¢–µ–∫—Å—Ç: {text_corpus}"
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_KEY}"
    try:
        response = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}]}, headers={"Content-Type": "application/json"})
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"–û—à–∏–±–∫–∞ AI: {response.text}"
    except Exception as e:
        return f"–°–±–æ–π: {e}"

# --- –ü–ê–†–°–ò–ù–ì ---
def process_videos(api_key, urls):
    youtube = build('youtube', 'v3', developerKey=api_key)
    all_data = []
    file_name = "comments.xlsx"
    for i, url in enumerate(urls):
        if "v=" in url: v_id = url.split("v=")[1].split("&")[0]
        elif "youtu.be/" in url: v_id = url.split("youtu.be/")[1].split("?")[0]
        else: continue
        try:
            vid_req = youtube.videos().list(part="snippet", id=v_id).execute()
            if vid_req['items']: file_name = f"{re.sub(r'[^\w\s-]', '', vid_req['items'][0]['snippet']['title'])[:30]}.xlsx"
            req = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=100)
            while req:
                resp = req.execute()
                for item in resp['items']: all_data.append({'–ê–≤—Ç–æ—Ä': item['snippet']['topLevelComment']['snippet']['authorDisplayName'], '–¢–µ–∫—Å—Ç': item['snippet']['topLevelComment']['snippet']['textDisplay']})
                req = youtube.commentThreads().list_next(req, resp)
        except: pass
    return all_data, file_name

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title("YouTube Parser Debug üõ†Ô∏è")

raw_urls = st.text_area("–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ:", height=100)
use_ai = st.toggle("–ü–æ–¥–∫–ª—é—á–∏—Ç—å AI-–∞–Ω–∞–ª–∏–∑", value=False)
debug_mode = st.checkbox("–†–µ–∂–∏–º –≥–ª—É–±–æ–∫–æ–π –æ—Ç–ª–∞–¥–∫–∏ (–ü–æ–∫–∞–∑–∞—Ç—å –æ—à–∏–±–∫—É)")

if debug_mode:
    if st.button("üî¥ –¢–ï–°–¢ –°–û–ï–î–ò–ù–ï–ù–ò–Ø –° AI"):
        result = debug_gemini_connection()
        st.markdown(result)

if st.button("–ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É", type="primary"):
    if not raw_urls: st.warning("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É")
    else:
        with st.spinner('–ü–∞—Ä—Å–∏–º...'):
            data, fname = process_videos(API_KEY, raw_urls.split('\n'))
        
        if data:
            summary = None
            if use_ai:
                with st.spinner('AI –¥—É–º–∞–µ—Ç...'):
                    summary = get_ai_summary(data)
                
                if "–û—à–∏–±–∫–∞" in summary or "–°–±–æ–π" in summary:
                    st.error(summary)
                else:
                    st.success("–ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤!")
                    st.markdown(summary)

            df = pd.DataFrame(data)
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer: df.to_excel(writer, index=False)
            send_results_to_telegram(buffer.getvalue(), fname, summary)
            st.download_button("–°–∫–∞—á–∞—Ç—å Excel", buffer.getvalue(), fname)
